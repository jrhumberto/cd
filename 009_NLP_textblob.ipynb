{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "009_NLP_textblob.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBw603duGV0B8LqH+S9o47",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrhumberto/cd/blob/main/009_NLP_textblob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glossário\n",
        "<ul>\n",
        "<li><a href=\"#introduction\">Introduction</a></li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "-oin9e-pA9yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction <a id='introduction'></a>"
      ],
      "metadata": {
        "id": "PuiJFQcWBaiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonte:\n",
        "- https://medium.com/@viniljf/criando-um-classificador-para-processamento-de-linguagem-natural-8dc27f3642a1\n",
        "- https://medium.com/@viniljf/criando-um-analisador-de-sentimentos-para-tweets-a53bae0c5147"
      ],
      "metadata": {
        "id": "WuNMpnSCRNNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4g3xFWwR8ra",
        "outputId": "e74560e6-8a25-4ce6-cfdc-dcb46f418928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWOENcCkRJVD",
        "outputId": "55bdf30a-b91c-4ada-dbf4-2b1c543880f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esta frase é de caráter:negativo\n",
            "Precisão da previsão:0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from textblob import TextBlob\n",
        "\n",
        "train_set = [\n",
        "    ('Eu adoro comer hamburguer', 'positivo'),\n",
        "    ('Este lugar é horrível', 'negativo'),\n",
        "    ('Você é uma pessoa adorável', 'positivo'),\n",
        "    ('Você é uma pessoa horrível', 'negativo'),\n",
        "    ('A festa está ótima', 'positivo'),\n",
        "    ('A festa está péssima', 'negativo'),\n",
        "    ('Este lugar é maravilhoso', 'positivo'),\n",
        "    ('Estou cansado disso.', 'negativo'),\n",
        "    ('Eu te odeio', 'negativo'),\n",
        "    ('Eu te adoro', 'positivo'),\n",
        "    ('Eu te amo', 'positivo'),\n",
        "    ('Você é incrível','positivo'),\n",
        "    ('Eu estou com muita raiva','negativo'),\n",
        "    ('Eu odeio essa linguagem','negativo'),\n",
        "    ('Essa linguagem é fantátisca','positivo'),\n",
        "    ('Essa linguagem é muito boa','positivo'),\n",
        "    ('Que comida gostosa','positivo'),\n",
        "    ('Que comida horrível','negativo'),\n",
        "    ('Estou me sentindo ótimo','positivo'),\n",
        "    ('Hoje eu estou péssimo','negativo')\n",
        "]\n",
        "test_set = [\n",
        "    ('Ótima linguagem', 'positivo'),\n",
        "    ('Péssima essa linguagem', 'negativo'),\n",
        "    ('Você é horrível', 'negativo'),\n",
        "    ('Comida gostosa!', 'positivo'),\n",
        "    ('Que raiva!', 'negativo'),\n",
        "    ('Ótima festa!', 'positivo'),\n",
        "    ('Eu não odeio todo mundo','positivo')\n",
        "]\n",
        "\n",
        "cl = NaiveBayesClassifier(train_set)\n",
        "accuracy = cl.accuracy(test_set)\n",
        "\n",
        "frase = 'Eu não odeio todo mundo'\n",
        "\n",
        "blob = TextBlob(frase,classifier=cl)\n",
        "\n",
        "print('Esta frase é de caráter:{}'.format(blob.classify()))\n",
        "print('Precisão da previsão:{}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "\n",
        "consumer_key = 'yAL0H3XVN3TFmZtSXxONNAuLJ'\n",
        "consumer_secret = '79OuTu1LvgmmiZERMKJ0pEHO6dmZx9M1ZU2AOi92x3clxUa14f'\n",
        "\n",
        "access_token = '54384307-XkH23t5V2scEApizDkjL1Dt9V7FRWnLryColjLX4j'\n",
        "access_token_secret = 'eHxk2mx6eNg5OcstPt8SslmCF6Gn56SfdQpCzMW70WUoD'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
        "auth.set_access_token(access_token,access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "#print(api.me())\n",
        "tweets = api.search('Emmanuel Macron')\n",
        "\n",
        "for tweet in tweets:\n",
        "    frase = TextBlob(tweet.text)\n",
        "\n",
        "    if frase.detect_language() != 'en':\n",
        "        traducao = TextBlob(str(frase.translate(to='en')))\n",
        "        print('Tweet: {0} - Sentimento: {1}'.format(tweet.text, traducao.sentiment))\n",
        "    else:\n",
        "        print('Tweet: {0} - Sentimento: {1}'.format(tweet.text, frase.sentiment))"
      ],
      "metadata": {
        "id": "nlAT1YuhR6gG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
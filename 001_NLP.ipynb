{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGnoSi4p7a5wKVI87sdaW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrhumberto/cd/blob/main/001_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonte: https://medium.com/@alegeorgelustosa/an%C3%A1lise-de-sentimentos-em-python-2a7d04a836e0"
      ],
      "metadata": {
        "id": "6p1A10DWeswB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import nltk \n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xcZbmBiFevNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "base_treinamento = [\n",
        "        ('este trabalho e agradável','alegria'),\n",
        "        ('gosto de ficar no seu aconchego','alegria'),\n",
        "        ('fiz a adesão ao curso hoj porque eu gostei','alegria'),\n",
        "        ('eu sou admirada por muitos','alegria'),\n",
        "        ('adoro como você é','alegria'),\n",
        "        ('adoro seu cabelo macio',alegria),\n",
        "        ('adoro a cor dos seus olhos','alegria'),\n",
        "        ('somos tão amáveis um com outro', 'alegria'),\n",
        "        ('sinto uma grenda afeição por ele','alegria'),\n",
        "        ('quero agradar meus filhos','alegria'),\n",
        "]"
      ],
      "metadata": {
        "id": "1YCS3Aq7evcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "exemplo_base = pd.DataFrame(base_treinamento)\n",
        "exemplo_base.columns =['Frase','Sentimento']"
      ],
      "metadata": {
        "id": "QcrDgsn3evta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "print(\"tamanho da base de treinamento\".format(exemplo_base.shape[0]))\n",
        "exemplo_base.Sentimento.value_counts()"
      ],
      "metadata": {
        "id": "C5MpVeDuev74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "print((exemplo_base.Sentimento.value_counts() / exemplo_base.shape[0])*100)"
      ],
      "metadata": {
        "id": "LXYcxi2eewWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "exemplo_base.sample(n=20)"
      ],
      "metadata": {
        "id": "SNn5knIvewij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "base_teste = [\n",
        "        ('não precisei pagar o ingresso','alegria'),\n",
        "        ('se eu ajeitar tudo fica bem','alegria'),\n",
        "        ('minha fortuna ultrapassa a sua','alegria'),\n",
        "        ('sou muito afortunado','alegria'),\n",
        "        ('e benefico para todos esta nova medida','alegria'),\n",
        "        ('ficou lindo',alegria),\n",
        "        ('achei esse sapato muito simpático','alegria'),\n",
        "        ('estou ansiosa pela sua chegada', 'alegria'),\n",
        "        ('congratulações pelo seu aniversário','alegria'),\n",
        "        ('delicadamente ele a colocou para dormir','alegria'),\n",
        "        ('a música é linda','alegria'),\n",
        "        ('sem música eu não vivo','alegria'),\n",
        "        ('conclui uma tarefa muito difícil','alegria')\n",
        "]"
      ],
      "metadata": {
        "id": "h3DkcArKewva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "exemplo_base_teste = pd.DataFrame(base_teste)\n",
        "exemplo_base_teste.columns = ['frase','Sentimento']\n",
        "print('Tamanho da base de teste: '.format(exemplo_base_teste.shape[0]))\n",
        "exemplo_base_teste.Sentimento.value_counts()"
      ],
      "metadata": {
        "id": "smuchIoOew6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "print((exemplo_base_teste.Sentimento.value_counts() / exemplo_base_teste.shape[0])*100)\n"
      ],
      "metadata": {
        "id": "pbdsJd9GexGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "lista_stop=nltk.corpus.stopwords.words('portuguese')\n",
        "np.transpose(lista_stop)"
      ],
      "metadata": {
        "id": "fZblFnPhexRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11\n",
        "lista_stop.append('tipo')\n",
        "lista_stop.append('tão')\n",
        "lista_stop.append('tudo')\n",
        "lista_stop.append('vai')"
      ],
      "metadata": {
        "id": "5oaKlN92exfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12\n",
        "#########################################################"
      ],
      "metadata": {
        "id": "pRVpqUJjexrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13\n",
        "def removeStopWords(texto):\n",
        "    frases = []\n",
        "    for (palavras, sentimento) in texto:\n",
        "        semStop=[p for p in palaveras.split() if p not in lista_stop]\n",
        "        frases.append((semStop, sentimento))\n",
        "        \n",
        "    return frases"
      ],
      "metadata": {
        "id": "Deppp9Zgex3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "#14    \n",
        "def aplica_stemmer(texto):\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    frases_sem_stemming = []\n",
        "    for (palavras, sentimento) in texto:\n",
        "        com_stemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in lista_stop]\n",
        "        frases_sem_stemming.append((com_stemming,sentimentos))\n",
        "    return frases_sem_stemming\n",
        "    "
      ],
      "metadata": {
        "id": "5GEDfKwxeyFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15\n",
        "frases_com_stem_treinamento = aplica_Stemmer(base_treinamento)"
      ],
      "metadata": {
        "id": "rxd7E-SBeyS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16\n",
        "pd.DataFrame(frases_com_stem_treinamento, columns=['Frase','Sentimento']).sample(10)"
      ],
      "metadata": {
        "id": "1Z3z3BxNeygZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17\n",
        "frases_com_stem_teste = aplica_Stemmer(base_teste)"
      ],
      "metadata": {
        "id": "BjYoUM5FeytQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18\n",
        "def busca_palavras(frases):\n",
        "    todas_apalvras = []\n",
        "    for (palavras,sentimento) in frases:\n",
        "        todas_palavras.append(palavras)\n",
        "    return todas_palavras"
      ],
      "metadata": {
        "id": "PZ3CKo_tey-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19 \n",
        "palavras_treinamento = busca_palavras(frases_com_stem_treinamento)\n",
        "palavras_teste = busca_palavras(frases_com_stem_teste)"
      ],
      "metadata": {
        "id": "wPZU-ed1ezLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20\n",
        "print(\"Quantidade de palavras na base de treinamento: {}\".format(pd.DataFrame(palavras_treinamento).count()))"
      ],
      "metadata": {
        "id": "uqBhgiiHezbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21\n",
        "def busca_frequencia(palavras):\n",
        "    palavras = nltk.FreqDist(palavras)\n",
        "    return palavras\n",
        "    "
      ],
      "metadata": {
        "id": "lekVmV47ezpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "#22\n",
        "frequencia_treinamento = busca_frequencia(palavras_treinamento)"
      ],
      "metadata": {
        "id": "fdR_BI7pez2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23\n",
        "frequencia_treinamento.most_common(20)"
      ],
      "metadata": {
        "id": "4L5qgFBQe0Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24\n",
        "frequencia_teste = busca_frequencia(palavras_teste)"
      ],
      "metadata": {
        "id": "8sPkHNaXe0RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25\n",
        "def busca_palavras_unicas(frequencia):\n",
        "    frequencia = frequencia.keys()\n",
        "    return freq"
      ],
      "metadata": {
        "id": "ydsGvqUFe0e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26\n",
        "def extrator_palavras(documento):\n",
        "    doc = set(documento)\n",
        "    caracteristicas = {}\n",
        "    for palavras in palavras_unicas_treinamento:\n",
        "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
        "    return caracteristicas"
      ],
      "metadata": {
        "id": "7AV2hKV8e0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27    \n",
        "def extrator_palavras_teste(documento):\n",
        "    doc = set(documento)\n",
        "    caracteristicas = {}\n",
        "    for palavras in palavras_unicas_teste:\n",
        "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
        "    return caracteristicas"
      ],
      "metadata": {
        "id": "F8Z7vCGIe07i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#28\n",
        "base_completa_treinamento = nltk.classify.apply_features(extrator_palavras, frases_com_stem_treinamento)\n",
        "base_completa_teste = nltk.classify.apply_features(extrator_palavras_teste, frases_com_stem_teste)"
      ],
      "metadata": {
        "id": "kVA4dtQae1J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#29\n",
        "###############################################################"
      ],
      "metadata": {
        "id": "L_Cy9inye1Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#30\n",
        "classificador = nltk.NaiveBayesClassifier.train(base_completa_treinamento)"
      ],
      "metadata": {
        "id": "OFnWyJ0Fe1kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#31\n",
        "print(classificador.labels())\n"
      ],
      "metadata": {
        "id": "mt6Vgu_qe1uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#32\n",
        "print(classificador.show_mostInformative_features(10))"
      ],
      "metadata": {
        "id": "ZdvR5Vi3e19O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#33\n",
        "print(nltk.classifiy.accuracy(classificador, base_completa_teste))"
      ],
      "metadata": {
        "id": "YJ4Cw7Ghe2J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#34\n",
        "erros = []\n",
        "for (frase,classe) in base_completa_teste:\n",
        "    resultado = classificador.classify(frase)\n",
        "    if resultado != classe:\n",
        "        erros.append((classe, resultado,frase))"
      ],
      "metadata": {
        "id": "CC0aAVZwe2Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#35\n",
        "from nltk.metrics import ConfusionMatrix\n",
        "esperado = []\n",
        "previsto = []\n",
        "for (frase, classe) in base_completa_teste:\n",
        "    resultado = classificador.classify(frase)\n",
        "    previsto.append(resultado)\n",
        "    esperado.append(classe)\n",
        "    \n",
        "matriz = ConfusionMatrix(esperado,previsto)\n",
        "print(matriz)"
      ],
      "metadata": {
        "id": "JFY9h2hee2kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#36\n",
        "teste = \"Nossa, que notícia maravilhosa!\"\n",
        "teste_stemming = []\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "for (palavras_treinamento) in teste.split():\n",
        "    com_stem = [p for o in palavras_treinamento.split()]\n",
        "    teste_stemming.append(str(stemmer.stem(comStem[0])))\n",
        "    \n",
        "novo = estrator_palavras(testeStemming)\n",
        "distribuicao = classificador.prob_classifiy(novo)\n",
        "for classe in distribuicao.samples():\n",
        "    print(\"%s : %f\"%(classe, distribuicao.prob(classe)))"
      ],
      "metadata": {
        "id": "luJ5R2Xde2ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#37\n",
        "teste = \"Pqp, que Trânsito chato da porra!\"\n",
        "teste_stemming = []\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "for (palavras_treinamento) in teste.split():\n",
        "    com_stem = [p for o in palavras_treinamento.split()]\n",
        "    teste_stemming.append(str(stemmer.stem(comStem[0])))\n",
        "    \n",
        "novo = estrator_palavras(testeStemming)\n",
        "distribuicao = classificador.prob_classifiy(novo)\n",
        "for classe in distribuicao.samples():\n",
        "    print(\"%s : %f\"%(classe, distribuicao.prob(classe)))"
      ],
      "metadata": {
        "id": "rzcE8Tige2_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}